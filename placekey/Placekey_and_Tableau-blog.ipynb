{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with Placekey (and Tableau)\n",
    "\n",
    "[Placekey](http://placekey.io) is a new open initiative from [Safegraph](http://safegraph.com).  Placekey provides a unique, standard identifier for physical places (a \"where\") AS WELL AS a \"what\" component to track the details for known points-of-interest (POIs).  The [\"Why Placekey\"](https://assets.website-files.com/5f08ccbb93b299154d34ef7f/5f781dacb8dbcb6d2944a8e0_Why%20Placekey%20-%20Technical%20White%20Paper%20V3.pdf) white paper does a great job at documenting the standard and structure of Placekey coordinates, so I won't do that here - and will just focus on the fun parts of how to use Python to interact with Placekey and how to turn the Placekey information into data that you can work with in Tableau!\n",
    "\n",
    "In this Notebook, I'm going to walk through some of the common tasks that you might want to do in working with Placekey to return data that you can use to augment your Tableau workflows.\n",
    "\n",
    "My goal here _is not_ to provide the end-to-end example in Tableau Prep or as a script that you call from Tableau, but to simply walk through a variety of the functions that you may want to use in your workflows.\n",
    "\n",
    "My super collaborator, Paul Rossman, is providing an example of Placekey in Tableau Prep to show off the functionality and a use case there!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before I go to far, here are some good places for background reading:\n",
    "\n",
    "### Libraries and links of interest\n",
    "\n",
    "* [Placekey API documents](https://docs.placekey.io/#intro) - What is the Placekey API? What can you do with it?\n",
    "* [Placekey on PyPI](https://pypi.org/project/placekey/0.0.4/)\n",
    "* [About Uber's H3](https://eng.uber.com/h3/) - Uber's Hexagonal Hierarchical Spatial Index \n",
    "* [H3 Python library](https://github.com/uber/h3-py) - H3 Python library GitHub Repo\n",
    "* [Helpful H3 Jupyter Notebooks](https://github.com/uber/h3-py-notebooks) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import some libraries!\n",
    "We'll use a series of Python libraries to work with our data... \n",
    "\n",
    "* _placekey_ - the Placekey library, because it's easy to use to faciliate the translation between Placekey codes and H3 geometries\n",
    "* _h3_ - the Uber H3 python library.  I'm using this to tap into geometries for the \"Where\" component of Placekey\n",
    "* _requests_ - to allow us to call out to the Placekey API.  There are numerous libraries that you can use - I like requests, Paul uses  http.client  Use whatever you like and that works for you!\n",
    "* _shapely_ - I <3 Shapely!  It's my go-to spatial library for all.the.things.  I'm using it here specifically for Point and Polygon geometries\n",
    "\n",
    "If you're just going to be playing around with this, I'd recommend creating a virtual environment with these libraries...but you do whatever you like to do with your Python "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h3\n",
    "import json\n",
    "import placekey as pk\n",
    "import requests\n",
    "from shapely.geometry import Point, Polygon\n",
    "from shapely.ops import transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # I'm also going to use Leaflet to do some mapping in this notebook, so...\n",
    "# !jupyter labextension install @jupyter-widgets/jupyterlab-manager\n",
    "# !jupyter labextension install jupyter-leaflet\n",
    "\n",
    "# irritating namespace problem with ipyleaflet in that I want to use a module named 'Polygon' and that will conflict with shapely's Polygon\n",
    "# so I'm just importing ALL THE STUFF!\n",
    "import ipyleaflet as leaflet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make sure you have Placekey developer credentials\n",
    "You'll need a Placekey API to use the API\n",
    "\n",
    "If you already have a developer account, you can just log into the [developer portal](https://dev.placekey.io/default/dashboard) and grab your API key, but if you don't...\n",
    "\n",
    "**Get set up with a Placekey account!**  It's free to set up a Placekey developer account - just [register for an API key](https://dev.placekey.io/default/register) and then sign into the Developer Portal to copy your API key.\n",
    "\n",
    "If you're lazy and don't plan on sharing your code or putting it up on a repo somewhere that others can get into it, you can be lazy and just hard-code your API key in your script...but otherwise, you should probably do something a bit smarter.  Maybe read up on Python [secrets](https://docs.python.org/3/library/secrets.html) and using [environment variables](https://dev.to/biplov/handling-passwords-and-secret-keys-using-environment-variables-2ei0) for your passwords?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lazy coder - don't share files with your actual API publicly\n",
    "API_KEY = \"YOUR_API_KEY_GOES_HERE\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set up for calling out to the API\n",
    "\n",
    "The API has a base URL that we'll use for ALL calls to it, so we can go ahead and set that\n",
    "\n",
    "And we will use the same general 'header' information in any of our calls, so we can set that up in advance too"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://api.placekey.io/v1/placekey\"\n",
    "\n",
    "headers = {\n",
    "    \"apikey\": API_KEY,\n",
    "    \"content-type\": \"application/json\"\n",
    "    } "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explore different ways that you can input location to Placekey\n",
    "\n",
    "There are a few different ways that you can define a location to retrieve a Placekey, so let's try out some options!\n",
    "\n",
    "* Latitude & Longitude - maybe you know an exact location... \n",
    "* Street Address - maybe you just know an address...\n",
    "* Street Address w/ POI information - this is great for when you have lots of locations at the same address...for instance a tall building with a bunch of businesses\n",
    "\n",
    "I've formatted each of these so they can go directly into a request as a query to Placekey....\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "payloads = {\n",
    "    # If you just have lat/lng values\n",
    "    \"lat_lng\": '''{ \n",
    "        \"query\": {\n",
    "            \"latitude\": 47.647174,\n",
    "            \"longitude\": -122.338222\n",
    "        }\n",
    "    }''',\n",
    "\n",
    "    # if you have an address\n",
    "    \"address\": ''' {\n",
    "        \"query\" : {\n",
    "            \"street_address\": \"1621 N. 34th Street\",\n",
    "            \"city\": \"Seattle\",\n",
    "            \"region\": \"WA\",\n",
    "            \"postal_code\": \"98103\",\n",
    "            \"iso_country_code\": \"US\"\n",
    "        }\n",
    "    }''',\n",
    "\n",
    "    # if you have an address and a name (I have two POIs here...each for different named locations at same address)\n",
    "    \"poi_1\": '''{\n",
    "      \"query\": {\n",
    "        \"query_id\": \"Studio Evolve\",\n",
    "        \"location_name\": \"Studio Evolve\",\n",
    "        \"street_address\": \"3333 Wallingford Ave N\",\n",
    "        \"city\": \"Seattle\",\n",
    "        \"region\": \"WA\",\n",
    "        \"postal_code\": \"98103\",\n",
    "        \"iso_country_code\": \"US\"\n",
    "      }\n",
    "    }''',\n",
    "    \n",
    "    \"poi_2\": '''{\n",
    "      \"query\": {\n",
    "        \"query_id\": \"MiiR\",\n",
    "        \"location_name\": \"MiiR\",\n",
    "        \"street_address\": \"3400 Stone Way N\",\n",
    "        \"city\": \"Seattle\",\n",
    "        \"region\": \"WA\",\n",
    "        \"postal_code\": \"98103\",\n",
    "        \"iso_country_code\": \"US\"\n",
    "      }\n",
    "    }''',\n",
    "    \n",
    "    \"poi_3\": '''{\n",
    "      \"query\": {\n",
    "        \"query_id\": \"Claret\",\n",
    "        \"location_name\": \"Claret Wine Bar\",\n",
    "        \"street_address\": \"3400 Stone Way N\",\n",
    "        \"city\": \"Seattle\",\n",
    "        \"region\": \"WA\",\n",
    "        \"postal_code\": \"98103\",\n",
    "        \"iso_country_code\": \"US\"\n",
    "      }\n",
    "    }''',\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Great, now let's actually ask Placekey for some information on these locations!\n",
    "\n",
    "All we have to do is send a formatted request over to Placekey - the request requires the URL, the query location information, and a set of headers (that we created earlier ^^^)\n",
    "\n",
    "If all works as we expect, we should get a <Response [200]> in return...which tells us that the request successfully returned a result\n",
    "\n",
    "Placekey uses standard error codes to tell you about the status of your request:\n",
    "\n",
    "* **200 - OK** - The request was successful\n",
    "* **400 - Bad Request** - The request is invalid. Read the message or error fields in the response for information on how to correct it.\n",
    "* **401 - Unauthorized** - Your API key is invalid. Check that you haven't removed it and that you've used the right header: apikey\n",
    "* **429 - Too Many Requests** - You have exceeded the permitted rate-limit. Check your dashboard to see how many requests have been made recently.\n",
    "* **50x - Internal Server Error** - An error occurred within our API. If this occurs, you may need to contact us to resolve the issue.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.post(\n",
    "    url, \n",
    "    payloads[\"lat_lng\"], \n",
    "    headers=headers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For reference, that query was for our data in lat/lng... the input looked like this:\n",
    "\n",
    "```\n",
    "\n",
    "         \"query\": {\n",
    "             \"latitude\": 47.647866,\n",
    "             \"longitude\": -122.338030\n",
    "         }\n",
    "\n",
    "```\n",
    "\n",
    "Once we have the response, we can check to make sure it's valid, and then dig into the results that we received...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# you can check the status code of the response (see descriptions above)\n",
    "response.status_code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "It's easy to pull the results out by looking at the JSON returned in the response\n",
    "\n",
    "We'll get two parts - the 'query_id' (we didn't give our query an ID) and the placekey (which returns as a what@where) - the WHAT (if identified) is the part before the @ and the WHERE is the part after the @"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"query_id\":\"0\",\"placekey\":\"@5x4-4b3-wc5\"}'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# you can check the text of the response\n",
    "response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query_id': '0', 'placekey': '@5x4-4b3-wc5'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# you can get the response as a JSON string\n",
    "response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Date': 'Thu, 15 Oct 2020 02:18:52 GMT', 'Content-Type': 'application/json', 'Content-Length': '42', 'Connection': 'keep-alive', 'Set-Cookie': '__cfduid=d4a439e16de0e2a4e37679e04d0c3d4ea1602728332; expires=Sat, 14-Nov-20 02:18:52 GMT; path=/; domain=.placekey.io; HttpOnly; SameSite=Lax; Secure', 'X-RateLimit-Limit-second': '100', 'X-RateLimit-Remaining-second': '99', 'X-RateLimit-Limit-minute': '1000', 'X-RateLimit-Remaining-minute': '999', 'Via': 'kong/1.5.0.4-enterprise-edition', 'X-B3-TraceId': '327cba3c959c456c803d9bcd49e5e8', 'Access-Control-Allow-Origin': '*', 'X-Kong-Upstream-Latency': '3', 'X-Kong-Proxy-Latency': '2', 'CF-Cache-Status': 'DYNAMIC', 'cf-request-id': '05cba6a4a00000139ad0b52000000001', 'Expect-CT': 'max-age=604800, report-uri=\"https://report-uri.cloudflare.com/cdn-cgi/beacon/expect-ct\"', 'Report-To': '{\"endpoints\":[{\"url\":\"https:\\\\/\\\\/a.nel.cloudflare.com\\\\/report?lkg-colo=28&lkg-time=1602728333\"}],\"group\":\"cf-nel\",\"max_age\":604800}', 'NEL': '{\"report_to\":\"cf-nel\",\"max_age\":604800}', 'Server': 'cloudflare', 'CF-RAY': '5e260d4dc924139a-SEA'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# you can even get a ton of detailed information if you really want to dig in...\n",
    "response.headers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Try it out with other address types!\n",
    "\n",
    "I set up four examples locations for queries - one with latitude/longitude, one with an address, and two with different POIs at the same address.  You can see how the returns differ...\n",
    "\n",
    "Notice that with the two queries with POIs I added in a 'query_id' as well - that lets you name the specific query result. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'query_id': '0', 'placekey': '@5x4-4b3-wc5'},\n",
       " {'query_id': '0', 'placekey': '225@5x4-4b3-wc5'},\n",
       " {'query_id': 'Studio Evolve', 'placekey': 'zzw-222@5x4-4b3-wkz'},\n",
       " {'query_id': 'MiiR', 'placekey': 'zzw-224@5x4-4b3-x89'},\n",
       " {'query_id': 'Claret', 'placekey': 'zzw-225@5x4-4b3-x89'}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's just load them all up into an array\n",
    "responses = []\n",
    "for payload_name in payloads:\n",
    "    response = requests.post(\n",
    "            url, \n",
    "            payloads[payload_name], \n",
    "            headers=headers)\n",
    "       \n",
    "    responses.append(response.json())\n",
    "\n",
    "responses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What can I do with this?\n",
    "\n",
    "It's great to have a Placekey, but how would I get it on the map?\n",
    "\n",
    "The Placekey WHERE component connects to an Uber H3 hexagonal region.  We can grab the polygon or the point centroid easily and have a location that we can now map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the Placekey so that we have a WHERE and a WHAT part.  I'm going to use some constants to make it easier to remember which part is which...\n",
    "WHAT = 0\n",
    "WHERE = 1\n",
    "\n",
    "# Note that in this first example, I'm just grabbing the first element from responses[] \n",
    "pk_code = responses[0]['placekey'].split('@')\n",
    "pk_what = pk_code[WHAT]\n",
    "pk_where = pk_code[WHERE]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'POINT (47.6470969240249858 -122.3382293588681335)'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the centroid for the H3 polygon\n",
    "pk_centroid = Point(pk.placekey_to_geo(pk_where))\n",
    "# Turn it into Well-Known Text (WKT) so that we can easily dump it into a .hyper file later if we want\n",
    "pk_centroid_wkt = pk_centroid.to_wkt()\n",
    "\n",
    "pk_centroid_wkt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'POLYGON ((47.6465019641238001 -122.3380000457549244, 47.6469746280718383 -122.3372893212373640, 47.6475695862356616 -122.3375186315465157, 47.6476918775630480 -122.3384586749290293, 47.6472192114175002 -122.3391693941204892, 47.6466242561420898 -122.3389400752557208, 47.6465019641238001 -122.3380000457549244))'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the polygon for the H3 hexagon\n",
    "h3_code = pk.placekey_to_h3(pk_where)\n",
    "pk_poly = Polygon(h3.h3_to_geo_boundary(h3_code))\n",
    "# Turn it into WKT so that we can dump it into a .hyper file later if we want\n",
    "pk_poly_wkt = pk_poly.to_wkt()\n",
    "\n",
    "pk_poly_wkt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's turn this into a map!!!\n",
    "\n",
    "I'm going to use the ipyleaflet library to draw some quick maps so that we can look at the H3 polygons that are returned\n",
    "\n",
    "We'll start with one polygon from the lat/lng coordinate input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "071dbc82066c4c2f9dcc338575a01134",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map(center=[47.647096924024986, -122.33822935886813], controls=(ZoomControl(options=['position', 'zoom_in_text…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "polygon = leaflet.Polygon(\n",
    "    locations=list(pk_poly.exterior.coords),\n",
    "    color=\"orange\", \n",
    "    fill_color=\"orange\"\n",
    ")\n",
    "\n",
    "# center the map using the centroid for the h3 hexagon\n",
    "m = leaflet.Map(center=(list(pk_centroid.coords)[0]), zoom=19)\n",
    "m.add_layer(polygon);\n",
    "\n",
    "display(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Map them all\n",
    "\n",
    "Or we can just run through all of the data we returned and map them all.\n",
    "\n",
    "A nice thing about this is that because the polygons that overlap are a bit transparent the opacity will tell you something about how many points fell into each h3 polygon.  \n",
    "\n",
    "On the map that is generated below you'll see three hexagons, but two of them are darker than the third...because there are two points that fall into each of those two hexagons, and only one that falls into the other.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ae57eddf3844218b524463d988b0809",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map(center=[47.647096924024986, -122.33822935886813], controls=(ZoomControl(options=['position', 'zoom_in_text…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "polys = []\n",
    "map2 = leaflet.Map(center=(list(pk_centroid.coords)[0]), zoom=16)\n",
    "\n",
    "for response in responses:\n",
    "    pk_code = response['placekey'].split('@')\n",
    "    \n",
    "    # Get the polygon for the H3 hexagon\n",
    "    h3_code = pk.placekey_to_h3(pk_code[WHERE])\n",
    "    pk_poly = Polygon(h3.h3_to_geo_boundary(h3_code))\n",
    "    \n",
    "    polys.append(list(pk_poly.exterior.coords))\n",
    "    \n",
    "    polygon = leaflet.Polygon(\n",
    "        locations=list(pk_poly.exterior.coords),\n",
    "        color=\"red\", \n",
    "        fill_color=\"red\",\n",
    "        fill_opacity=0.5\n",
    "    )\n",
    "    \n",
    "    map2.add_layer(polygon)\n",
    "\n",
    "\n",
    "display(map2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This is nice and all, but how about some Tableau?\n",
    "\n",
    "Yeah, yeah, we can do some stuff with Python and make little maps in a Jupyter notebook, but how does this help me in Tableau?  \n",
    "\n",
    "1. Paul Rossman has a great Python script as part of this blog that demonstrates a Tableau Prep workflow \n",
    "2. It's SO easy to use the Tableau Hyper API to write this data to some .hyper files and just drop it straight into Tableau and go to town... so let's do it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tableauhyperapi import HyperProcess, Telemetry, Connection, CreateMode, TableDefinition, Inserter, TableName, SqlType, escape_name\n",
    "# but this also uses the imports from the top of this notebook, so if you move this into a standalone script, remember to import everything you need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# and adding a little helper function to deal with some polygon weirdness below\n",
    "# this just flips the coordinate order in a polygon to standardize the WKT\n",
    "# if your wkt is already nice and correct, you don't need to do this\n",
    "def flip(x, y):\n",
    "    return y, x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to write a Hyper file with two tables:\n",
    "* H3 geometry and codes (since multiple locations in our input table can match to the same polygon, there's no point in bloating our table by writing those polygons more than once)\n",
    "* Original data + Placekey WHAT and WHERE components that we can join to the table with H3 geometries\n",
    "\n",
    "To do this we'll set up our Hyper file, then magically drop in our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The data was added to the table.\n",
      "The connection to the Hyper extract file is closed.\n",
      "The HyperProcess has shut down.\n"
     ]
    }
   ],
   "source": [
    "HYPER_OUTPUT = 'myHyperFile.hyper'\n",
    "\n",
    "with HyperProcess(telemetry=Telemetry.SEND_USAGE_DATA_TO_TABLEAU) as hyper:\n",
    "    with Connection(hyper.endpoint, HYPER_OUTPUT, CreateMode.CREATE_AND_REPLACE) as connection:\n",
    "        # create a connection to your schema - named 'Placekey' here\n",
    "        connection.catalog.create_schema('Placekey')\n",
    "       \n",
    "        # create a table to drop the attribute data into ('OriginalData')\n",
    "        data_table = TableDefinition( TableName('Placekey','OriginalData'), [\n",
    "            TableDefinition.Column('query_id', SqlType.text()),\n",
    "            TableDefinition.Column('location_name', SqlType.text()),\n",
    "            TableDefinition.Column('street_address', SqlType.text()),\n",
    "            TableDefinition.Column('city', SqlType.text()),\n",
    "            TableDefinition.Column('region', SqlType.text()),\n",
    "            TableDefinition.Column('postal_code', SqlType.text()),\n",
    "            TableDefinition.Column('iso_country_code', SqlType.text()),\n",
    "            TableDefinition.Column('latitude', SqlType.double()),\n",
    "            TableDefinition.Column('longitude', SqlType.double()),\n",
    "            TableDefinition.Column('placekey_what', SqlType.text()),\n",
    "            TableDefinition.Column('placekey_where', SqlType.text()),\n",
    "        ])\n",
    "        \n",
    "        # create a table to drop the geometry into ('GeomData')\n",
    "        geom_table = TableDefinition( TableName('Placekey', 'GeomData'), [\n",
    "            TableDefinition.Column('placekey_where', SqlType.text()),\n",
    "            TableDefinition.Column('geom_h3', SqlType.geography()),\n",
    "        ])\n",
    "          \n",
    "    \n",
    "        # create the table\n",
    "        connection.catalog.create_table(data_table)\n",
    "        connection.catalog.create_table(geom_table)\n",
    "    \n",
    "    \n",
    "        # Do some special steps to create the table with spatial data\n",
    "        # inserter definition for the geography data\n",
    "        # See the hyperAPI docs on writing spatial data for more details\n",
    "        # https://help.tableau.com/current/api/hyper_api/en-us/docs/hyper_api_geodata.html\n",
    "        geom_inserter_definition = [\n",
    "            TableDefinition.Column('placekey_where', SqlType.text()),\n",
    "            TableDefinition.Column('geom_h3_as_text', SqlType.text())\n",
    "        ]\n",
    "        \n",
    "        # map the geom as text to the geom as geometry\n",
    "        column_mappings = [\n",
    "            'placekey_where',\n",
    "            Inserter.ColumnMapping('geom_h3', f'CAST({escape_name(\"geom_h3_as_text\")} AS GEOGRAPHY)')\n",
    "        ]\n",
    "    \n",
    "        # walk through the input info, get results, and then drop it into a row in the .hyper\n",
    "        # I'm doing this the crazy verbose way so it's clear what's happening, but you can simplify :)\n",
    "        with Inserter(connection, data_table) as data_inserter:\n",
    "            unique_pk_where = []\n",
    "            \n",
    "            for payload_name in payloads:\n",
    "                # we'll put everything into an array for each row...\n",
    "                row = []\n",
    "                geom_row = []\n",
    "\n",
    "                # get the response from Placekey for each payload - I'm just re-doing the steps above \n",
    "                # so that it's all in one workflow as a demo\n",
    "                response = requests.post(\n",
    "                        url, \n",
    "                        payloads[payload_name], \n",
    "                        headers=headers)           \n",
    "\n",
    "                # we know all the query details so can grab those quickly\n",
    "                payload_query = json.loads(payloads[payload_name])['query']\n",
    "\n",
    "                # and drop them into the array for a single row\n",
    "                row.append(payload_query.get(\"query_id\"))\n",
    "                row.append(payload_query.get(\"location_name\"))\n",
    "                row.append(payload_query.get(\"street_address\"))\n",
    "                row.append(payload_query.get(\"city\"))\n",
    "                row.append(payload_query.get(\"region\"))\n",
    "                row.append(payload_query.get(\"postal_code\"))\n",
    "                row.append(payload_query.get(\"iso_country_code\"))\n",
    "                row.append(payload_query.get(\"latitude\"))\n",
    "                row.append(payload_query.get(\"longitude\"))\n",
    "                \n",
    "                # now we just need to tack on the placekey results results as well           \n",
    "                pk_code = response.json()['placekey'].split('@')\n",
    "\n",
    "                # earlier in the notebook I set 'WHAT' = 0 and 'WHERE' = 1\n",
    "                # so if you're copy pasting this, make sure you set those!\n",
    "                pk_what = pk_code[WHAT]\n",
    "                pk_where = pk_code[WHERE]\n",
    "\n",
    "                # drop them into the array\n",
    "                row.append(pk_what)\n",
    "                row.append(pk_where)\n",
    "            \n",
    "                # and insert it all into a row\n",
    "                data_inserter.add_row(\n",
    "                    row\n",
    "                )\n",
    "                \n",
    "                # while we're here update our list of unique h3 codes in the results\n",
    "                if pk_where not in unique_pk_where:\n",
    "                    unique_pk_where.append(pk_where)\n",
    "                \n",
    "            # boom.  Executed.\n",
    "            data_inserter.execute()  \n",
    "\n",
    "        \n",
    "        # write the geom table using our set of unique h3 codes\n",
    "        with Inserter(connection, geom_table, column_mappings, inserter_definition=geom_inserter_definition) as geom_inserter:\n",
    "            \n",
    "            for where_code in unique_pk_where:\n",
    "                # and now we want to drop the geometry into the geom table\n",
    "                # Get the polygon for the H3 hexagon\n",
    "                h3_code = pk.placekey_to_h3(where_code)\n",
    "                \n",
    "                # so an interesting artifact of the h3.h3_to_geo_boundary() function is that it returns the coordinates\n",
    "                # as (lat, lng) instead of (lng, lat)\n",
    "                # while that was great up above when I used the ipyleaflet library to do some mapping\n",
    "                # since ipyleaflet seems to like the (lat, lng) ordering... other mapping tools prefer (lng, lat)\n",
    "                # so, we need to flip the vertices before we can write the WKT that we'll dump into .hyper\n",
    "                # I'm using a little flipper function here and the shapely transform function to do that.\n",
    "                # if your WKT are properly formed to begin with, you don't have to have that extra step \n",
    "                pk_poly_wkt = transform(flip, Polygon(h3.h3_to_geo_boundary(h3_code))).to_wkt()\n",
    "\n",
    "                geom_inserter.add_row(\n",
    "                    [where_code, pk_poly_wkt]\n",
    "                )\n",
    "\n",
    "            # boom.  Executed.\n",
    "            geom_inserter.execute()  \n",
    "\n",
    "        print(\"The data was added to the table.\")\n",
    "    print(\"The connection to the Hyper extract file is closed.\")\n",
    "print(\"The HyperProcess has shut down.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And that gives you a nice .hyper file with two tables - one with your original data and one with the geometries for the h3 polygons.  You can drop the .hyper straight into Tableau and explore.\n",
    "\n",
    "Of course, it would probably be more interesting with a real dataset and attribute set instead of five locations that I selected to be close together and that I know would fall into overlapping h3 polygons.  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tabpy_kernel",
   "language": "python",
   "name": "tabpy_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
